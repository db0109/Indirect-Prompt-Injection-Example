# Indirect-Prompt-Injection-Example
Indirect Prompt Injection 


The goal of this is to educate security practitioners on indirect prompt injection by recreating a very basic indirect prompt injection.

Indirect prompt injection involves Artificial intelligence ingesting a set of adversarial commands and then producing an unforeseen or undesirable outcome. 

In the indirect prompt injection included in this repo is a very basic one. When ChatGPT/Cluade/Bard ingest this document instead of properly analyzing the document the AI should instead sing a song about Avatar the last Air Bender. 

As the AI attack surface increases with products such as ChatGPT for enterprise and others it is important to understand these attacks and have defenses in place to mitigate risk. 

